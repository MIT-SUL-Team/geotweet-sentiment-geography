{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = 'stsb-xlm-r-multilingual-64'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "from io import StringIO \n",
    "import sys\n",
    "import torch\n",
    "\n",
    "class Capturing(list):\n",
    "    def __enter__(self):\n",
    "        self._stdout = sys.stdout\n",
    "        sys.stdout = self._stringio = StringIO()\n",
    "        return self\n",
    "    def __exit__(self, *args):\n",
    "        self.extend(self._stringio.getvalue().splitlines())\n",
    "        del self._stringio\n",
    "        sys.stdout = self._stdout\n",
    "\n",
    "if '.gitignore' not in os.listdir():\n",
    "    os.chdir('..')\n",
    "    \n",
    "from src.utils.emb_clf_setup_utils import clean_for_content, test_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = torch.load('models/clf.pkl')\n",
    "emb = torch.load('models/emb.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_set():\n",
    "    \n",
    "    df = pd.read_csv('data/labeled_data/training_1600000_processed_noemoticon.csv', encoding='latin', header=None, usecols=[0,5])\n",
    "    df.columns = ['label', 'text']\n",
    "    df['label'] = [0 if x==0 else 1 for x in df['label']]\n",
    "    df['lang'] = 'en'\n",
    "    df['text'] = [clean_for_content(text, lang) for text, lang in zip(df['text'], df['lang'])]\n",
    "    df = df[df['text']!=''].reset_index(drop=True)\n",
    "\n",
    "    embeddings = np.load('data/labeled_data/embeddings.npy')\n",
    "\n",
    "    with open('data/labeled_data/test_ids.txt', 'r') as fp:\n",
    "        test_ids = json.load(fp)\n",
    "        \n",
    "    test_df = df.loc[test_ids,:]    \n",
    "    test_embeddings = embeddings[test_ids,:]\n",
    "    \n",
    "    return test_df, test_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_alt_english():\n",
    "    df = pd.concat([\n",
    "        pd.read_csv('data/labeled_data/validation/test.csv'),\n",
    "        pd.read_csv('data/labeled_data/validation/train.csv')\n",
    "    ])\n",
    "    df = df[df['text'].notnull()].reset_index(drop=True)\n",
    "    del df['selected_text']\n",
    "    df['lang'] = 'en'\n",
    "    df.loc[df['sentiment']=='neutral', 'label'] = 0.5\n",
    "    df.loc[df['sentiment']=='negative', 'label'] = 0\n",
    "    df.loc[df['sentiment']=='positive', 'label'] = 1\n",
    "    df['text'] = [clean_for_content(text, lang) for text, lang in zip(df['text'], df['lang'])]\n",
    "    subset = df[df['label'].isin([1, 0])].reset_index(drop=True)\n",
    "    subset['label'] = subset['label'].astype(int)\n",
    "    return subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_alt_portuguese():\n",
    "    \n",
    "    df = pd.read_csv('data/labeled_data/validation/TweetSentBR.txt', sep='\\t')\n",
    "    df.columns = ['text', 'label']\n",
    "    df['lang'] = 'pt'\n",
    "    df = df[df['label'].isin([-1,1])].reset_index(drop=True)\n",
    "    df.loc[df['label']==-1, 'label'] = 0\n",
    "    df['text'] = [clean_for_content(text, lang) for text, lang in zip(df['text'], df['lang'])]\n",
    "    df = df[df['text']!=''].reset_index(drop=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_multilingual():\n",
    "    langs = glob.glob('data/labeled_data/validation/multilingual_twitter_sentiment_*.tsv')\n",
    "    langs = [lang.replace(\"data/labeled_data/validation/multilingual_twitter_sentiment_\", \"\") for lang in langs]\n",
    "    langs = [lang.replace(\".tsv\", \"\") for lang in langs]\n",
    "    langs.sort()\n",
    "\n",
    "    validation = {}\n",
    "\n",
    "    for lang in langs:\n",
    "        df = pd.read_csv(\n",
    "            'data/labeled_data/validation/multilingual_twitter_sentiment_{}.tsv'.format(lang), \n",
    "            sep='\\t'\n",
    "        )\n",
    "        df.rename(columns={'tweet_full': 'text'}, inplace=True)\n",
    "        df = df[df['label'].isin(['Positive', 'Negative'])]\n",
    "        df['label'] = [0 if x=='Negative' else 1 for x in df['label']]\n",
    "        df['text'] = [clean_for_content(text, lang) for text, lang in zip(df['text'], df['lang'])]\n",
    "        df = df[df['text']!=''].reset_index(drop=True)\n",
    "\n",
    "        validation[lang] = df\n",
    "    return validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_df, test_embeddings = get_test_set()\n",
    "alt_english = get_alt_english()\n",
    "alt_portuguese = get_alt_portuguese()\n",
    "multilingual = get_multilingual()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------\n",
      "\n",
      "Test Set\n",
      "Testing model...\n",
      "Got 253188 out of 320000 correct.\n",
      "Accuracy rate is 0.7912125\n",
      "Precision is 0.7871810367154644, Recall is 0.7980669442464708\n",
      "\n",
      "----------\n",
      "\n",
      "Alternative English\n",
      "Testing model...\n",
      "Got 16092 out of 18467 correct.\n",
      "Accuracy rate is 0.871392213136947\n",
      "Precision is 0.9122490412812994, Recall is 0.8351058337635519\n",
      "\n",
      "----------\n",
      "\n",
      "Alternative Portuguese\n",
      "Testing model...\n",
      "Got 8310 out of 11074 correct.\n",
      "Accuracy rate is 0.7504063572331587\n",
      "Precision is 0.7718365061590146, Recall is 0.8294223826714802\n",
      "\n",
      "----------\n",
      "\n",
      "Multilingual\n",
      "\n",
      " ALBANIAN\n",
      "Testing model...\n",
      "Got 1349 out of 1866 correct.\n",
      "Accuracy rate is 0.7229367631296891\n",
      "Precision is 0.8809338521400778, Recall is 0.7566844919786097\n",
      "\n",
      " BOSNIAN\n",
      "Testing model...\n",
      "Got 1477 out of 1872 correct.\n",
      "Accuracy rate is 0.7889957264957265\n",
      "Precision is 0.781387181738367, Recall is 0.859073359073359\n",
      "\n",
      " BULGARIAN\n",
      "Testing model...\n",
      "Got 797 out of 1101 correct.\n",
      "Accuracy rate is 0.7238873751135332\n",
      "Precision is 0.7008426966292135, Recall is 0.8457627118644068\n",
      "\n",
      " CROATIAN\n",
      "Testing model...\n",
      "Got 5648 out of 6890 correct.\n",
      "Accuracy rate is 0.8197387518142235\n",
      "Precision is 0.8666271487848252, Recall is 0.8855239248940037\n",
      "\n",
      " ENGLISH\n",
      "Testing model...\n",
      "Got 2649 out of 3152 correct.\n",
      "Accuracy rate is 0.8404187817258884\n",
      "Precision is 0.8345363686840644, Recall is 0.879976580796253\n",
      "\n",
      " GERMAN\n",
      "Testing model...\n",
      "Got 1518 out of 1865 correct.\n",
      "Accuracy rate is 0.8139410187667561\n",
      "Precision is 0.7667224080267558, Recall is 0.9309644670050762\n",
      "\n",
      " HUNGARIAN\n",
      "Testing model...\n",
      "Got 3124 out of 4071 correct.\n",
      "Accuracy rate is 0.7673790223532302\n",
      "Precision is 0.9078087375300997, Recall is 0.7953586497890295\n",
      "\n",
      " POLISH\n",
      "Testing model...\n",
      "Got 8469 out of 11049 correct.\n",
      "Accuracy rate is 0.7664947054032039\n",
      "Precision is 0.8021916268614779, Recall is 0.8297006684103458\n",
      "\n",
      " PORTUGUESE\n",
      "Testing model...\n",
      "Got 734 out of 1315 correct.\n",
      "Accuracy rate is 0.5581749049429657\n",
      "Precision is 0.4266487213997308, Recall is 0.6716101694915254\n",
      "\n",
      " RUSSIAN\n",
      "Testing model...\n",
      "Got 2690 out of 3592 correct.\n",
      "Accuracy rate is 0.7488864142538976\n",
      "Precision is 0.7378201908588649, Recall is 0.7944835045970795\n",
      "\n",
      " SERBIAN\n",
      "Testing model...\n",
      "Got 222 out of 345 correct.\n",
      "Accuracy rate is 0.6434782608695652\n",
      "Precision is 0.6945812807881774, Recall is 0.698019801980198\n",
      "\n",
      " SLOVAK\n",
      "Testing model...\n",
      "Got 5042 out of 6154 correct.\n",
      "Accuracy rate is 0.8193045173870653\n",
      "Precision is 0.8487579687843482, Recall is 0.9010501750291715\n",
      "\n",
      " SLOVENIAN\n",
      "Testing model...\n",
      "Got 4511 out of 5927 correct.\n",
      "Accuracy rate is 0.7610933018390417\n",
      "Precision is 0.6889480692410119, Recall is 0.9125220458553792\n",
      "\n",
      " SPANISH\n",
      "Testing model...\n",
      "Got 6658 out of 9247 correct.\n",
      "Accuracy rate is 0.7200173029090516\n",
      "Precision is 0.9431545236188951, Recall is 0.7250123092072871\n",
      "\n",
      " SWEDISH\n",
      "Testing model...\n",
      "Got 1879 out of 2590 correct.\n",
      "Accuracy rate is 0.7254826254826254\n",
      "Precision is 0.5774260151410874, Recall is 0.8963675213675214\n"
     ]
    }
   ],
   "source": [
    "with Capturing() as output:\n",
    "    print(\"\\n----------\\n\\nTest Set\")\n",
    "    test_model(clf, test_df, test_embeddings)\n",
    "\n",
    "    print(\"\\n----------\\n\\nAlternative English\")\n",
    "    embeddings = emb.encode(alt_english['text'].values)\n",
    "    test_model(clf, alt_english, embeddings)\n",
    "\n",
    "    print(\"\\n----------\\n\\nAlternative Portuguese\")\n",
    "    embeddings = emb.encode(alt_portuguese['text'].values)\n",
    "    test_model(clf, alt_portuguese, embeddings)\n",
    "\n",
    "    print(\"\\n----------\\n\\nMultilingual\")\n",
    "    for lang in multilingual.keys():\n",
    "        print(\"\\n\", lang.upper())\n",
    "        embeddings = emb.encode(multilingual[lang]['text'].values)\n",
    "        test_model(clf, multilingual[lang], embeddings)\n",
    "\n",
    "with open(\"models/{}.txt\".format(run), \"w\") as f:\n",
    "    for line in output:\n",
    "        print(line)\n",
    "        f.write(line)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
