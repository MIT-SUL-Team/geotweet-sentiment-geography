{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing File Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: @SirenaYu\n",
    "\n",
    "In missing_file_analysis, the following definition is used:\n",
    "\n",
    "* A file is defined as <b>missing</b> if the filepath does not exist in the directory.\n",
    "* A file is define as <b>empty</b> if the filepath exists but the file is empty.\n",
    "* A file is defined as <b>corrupted</b> if the number of posts it contains is less than the lower of 1) 10,000 or 2) the bottom 10th percentile number of posts from that year.\n",
    "\n",
    "The notebook generates the following reports:\n",
    "* Lists of missing files, empty files, and corrupted files each in the form of a csv file. Example of such csv file is attached in the notebook.\n",
    "* Number of missing files, empty files, and corrupted files from each year, stored in a dataframe. The dataframe is then stored as a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gzip\n",
    "from script import days_in_month, hours_in_day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2012, Geography Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_files = []\n",
    "empty_files = []\n",
    "num_posts = []\n",
    "\n",
    "for month in range(1, 13):\n",
    "    for day in range(1, days_in_month(month, 2012)+1):\n",
    "        for hour in range(24):\n",
    "            file_name = ''.join([\"/srv/data/twitter_geography/2012/geography_2012_\", str(month), \"_\", str(day).zfill(2), \"_\", str(hour).zfill(2), \".csv.gz\"])\n",
    "            if not os.path.exists(file_name):\n",
    "                missing_files.append(file_name)\n",
    "            else:\n",
    "                try: \n",
    "                    with gzip.open(file_name) as f:\n",
    "                        posts = pd.read_csv(f, sep=\"\\t\")\n",
    "                        num_posts.append(len(posts))\n",
    "                except pd.errors.EmptyDataError:\n",
    "                    empty_files.append(file_name)\n",
    "                    continue\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"There are a total of\", len(missing_files), \"missing files from 2012 geography files.\")\n",
    "print(\"There are a total of\", len(empty_files), \"empty files from 2012 geography files.\")\n",
    "print(\"The average number of posts from each file is\", sum(num_posts)/len(num_posts), \"from 2012 geography files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom_10_percentile = pd.Series(num_posts).quantile(0.1)\n",
    "threshold = min(10000, bottom_10_percentile)\n",
    "threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrupted_files = []\n",
    "\n",
    "for month in range(1, 13):\n",
    "    for day in range(1, days_in_month(month, 2012)+1):\n",
    "        for hour in range(24):\n",
    "            file_name = ''.join([\"/srv/data/twitter_geography/2012/geography_2012_\", str(month), \"_\", str(day).zfill(2), \"_\", str(hour).zfill(2), \".csv.gz\"])\n",
    "            if os.path.exists(file_name):\n",
    "                try: \n",
    "                    with gzip.open(file_name) as f:\n",
    "                        posts = pd.read_csv(f, sep=\"\\t\")\n",
    "                        if len(posts) < threshold:\n",
    "                            corrupted_files.append(file_name)\n",
    "                except pd.errors.EmptyDataError:\n",
    "                    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"There are a total of\", len(corrupted_files), \"corrputed files from 2012.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_files_df = pd.DataFrame(data=pd.Series(missing_files),\n",
    "                               columns=[\"missing_files\"])\n",
    "empty_files_df = pd.DataFrame(data=pd.Series(empty_files),\n",
    "                               columns=[\"empty_files\"])\n",
    "corrupted_files_df = pd.DataFrame(data=pd.Series(corrupted_files),\n",
    "                               columns=[\"corrupted_files\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of List of Missing Files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_files_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_files_df.to_csv(''.join([\"../output/missing_file_report/missing_files_\", str(2012), \"_geography.csv\"]))\n",
    "empty_files_df.to_csv(''.join([\"../output/missing_file_report/empty_files_\", str(2012), \"_geography.csv\"]))\n",
    "corrupted_files_df.to_csv(''.join([\"../output/missing_file_report/corrupted_files_\", str(2012), \"_geography.csv\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All years, 2012-2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saving_list_of_files(year, folder):\n",
    "    \"\"\"\n",
    "    @param year: int, year\n",
    "    @param folder: str, \"geography\" for geography folder, \"sentiment\" for sentiment folder\n",
    "    \"\"\"\n",
    "    missing_files = []\n",
    "    empty_files = []\n",
    "    num_posts = []\n",
    "    if folder == \"geography\":\n",
    "        path = \"/srv/data/twitter_geography/\"\n",
    "        prefix = \"geography\"\n",
    "    else:\n",
    "        path = \"/srv/data/twitter_sentiment/\"\n",
    "        prefix = \"bert_sentiment\"\n",
    "    file_name_to_num_post = dict()\n",
    "    \n",
    "    for month in range(1, 13):\n",
    "        for day in range(1, days_in_month(month, year)+1):\n",
    "            for hour in range(24):\n",
    "                file_name = ''.join([path, str(year), \"/\", prefix, \"_\", str(year), \"_\", str(month), \"_\", str(day).zfill(2), \"_\", str(hour).zfill(2), \".csv.gz\"])\n",
    "                if not os.path.exists(file_name):\n",
    "                    missing_files.append(file_name)\n",
    "                else:\n",
    "                    try: \n",
    "                        with gzip.open(file_name) as f:\n",
    "                            posts = pd.read_csv(f, sep=\"\\t\")\n",
    "                            num_posts.append(len(posts))\n",
    "                            file_name_to_num_post[file_name] = len(posts)\n",
    "                    except pd.errors.EmptyDataError:\n",
    "                        empty_files.append(file_name)\n",
    "                        continue\n",
    "                        \n",
    "    bottom_10_percentile = pd.Series(num_posts).quantile(0.1)\n",
    "    threshold = min(10000, bottom_10_percentile)\n",
    "    \n",
    "    corrupted_files = []\n",
    "    for month in range(1, 13):\n",
    "        for day in range(1, days_in_month(month, year)+1):\n",
    "            for hour in range(24):\n",
    "                file_name = ''.join([path, str(year), \"/\", prefix, \"_\", str(year), \"_\", str(month), \"_\", str(day).zfill(2), \"_\", str(hour).zfill(2), \".csv.gz\"])\n",
    "                if file_name in file_name_to_num_post:\n",
    "                    if file_name_to_num_post[file_name] < threshold:\n",
    "                        corrupted_files.append(file_name)\n",
    "    missing_files_df = pd.DataFrame(data=pd.Series(missing_files),\n",
    "                               columns=[\"missing_files\"])\n",
    "    empty_files_df = pd.DataFrame(data=pd.Series(empty_files),\n",
    "                               columns=[\"empty_files\"])\n",
    "    corrupted_files_df = pd.DataFrame(data=pd.Series(corrupted_files),\n",
    "                               columns=[\"corrupted_files\"])\n",
    "    missing_files_df.to_csv(''.join([\"../output/missing_file_report/missing_files_\", str(year), \"_\", folder,\".csv\"]))\n",
    "    empty_files_df.to_csv(''.join([\"../output/missing_file_report/empty_files_\", str(year), \"_\", folder, \".csv\"]))\n",
    "    corrupted_files_df.to_csv(''.join([\"../output/missing_file_report/corrupted_files_\", str(year), \"_\", folder, \".csv\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Lists of Missing, Empty, Corrupted Files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in range(2012, 2022):\n",
    "    saving_list_of_files(year, \"geography\")\n",
    "    saving_list_of_files(year, \"sentiment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Generating Missing File Report "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for year in range(2012, 2022):\n",
    "    for folder in [\"geography\", \"sentiment\"]:\n",
    "        missing_files_df = pd.read_csv(''.join([\"../output/missing_file_report/missing_files_\", str(year), \"_\", folder,\".csv\"]))\n",
    "        empty_files_df = pd.read_csv(''.join([\"../output/missing_file_report/empty_files_\", str(year), \"_\", folder, \".csv\"]))\n",
    "        corrupted_files_df = pd.read_csv(''.join([\"../output/missing_file_report/corrupted_files_\", str(year), \"_\", folder, \".csv\"]))\n",
    "        data.append([year, folder, len(missing_files_df), len(empty_files_df), len(corrupted_files_df)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_file_report_df = pd.DataFrame(data=data,\n",
    "                                     columns=[\"year\", \"folder\", \"num_missing_files\", \"num_empty_files\", \"num_corrupted_files\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_file_report_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_file_report_df.to_csv(\"../output/missing_file_report/missing_file_report.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
